{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "JST Genap_Tugas 2_Ni Nyoman Wahyuni Indraswari_F1D018047.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4GtOtwjD9pZm"
      },
      "source": [
        "### Preprocessing Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2uqq8mVJNMSs"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.neural_network import MLPClassifier \n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T7ofHWLH9pZs"
      },
      "source": [
        "dataset=[[1, 0, 0, 0, 1, 0],   \n",
        "       [0, 1, 1, 1, 1, 0],\n",
        "       [0, 0, 1, 0, 0, 1],\n",
        "       [0, 0, 1, 0, 1, 0],\n",
        "       [0, 1, 0, 0, 0, 1],\n",
        "       [1, 0, 1, 0, 1, 1],\n",
        "       [0, 0, 1, 1, 0, 0],\n",
        "       [0, 1, 0, 1, 0, 0],\n",
        "       [1, 0, 0, 1, 0, 1],\n",
        "       [0, 1, 1, 1, 1, 1]]\n",
        "cls = ['A', 'B', 'A','A','A','A','B','B','B','B']\n",
        " \n",
        "weights = [0.0, 0.0, 0.0, 0.0, 0.0, 0.0 ]"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sfhqUqPU9pZw",
        "outputId": "00aa68fb-4975-4485-cd83-18fecd498eed"
      },
      "source": [
        "target = np.array(cls)\n",
        "dataY = np.arange(len(target))\n",
        "dataY[:]=0\n",
        "id_dataY = np.where(target == 'A')\n",
        "dataY[id_dataY]=1\n",
        "dataY = dataY.tolist()\n",
        "dataY"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 0, 1, 1, 1, 1, 0, 0, 0, 0]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xqZ7rh4N9pZ2",
        "outputId": "9b668487-5324-4fe0-944d-b6e16d7f2eed"
      },
      "source": [
        "# transpose dataset \n",
        "dataset_aksen = list(map(list, zip(*dataset)))\n",
        "dataset_aksen.append(dataY)\n",
        "dataset_with_class = list(map(list, zip(*dataset_aksen)))\n",
        "dataset_with_class"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[1, 0, 0, 0, 1, 0, 1],\n",
              " [0, 1, 1, 1, 1, 0, 0],\n",
              " [0, 0, 1, 0, 0, 1, 1],\n",
              " [0, 0, 1, 0, 1, 0, 1],\n",
              " [0, 1, 0, 0, 0, 1, 1],\n",
              " [1, 0, 1, 0, 1, 1, 1],\n",
              " [0, 0, 1, 1, 0, 0, 0],\n",
              " [0, 1, 0, 1, 0, 0, 0],\n",
              " [1, 0, 0, 1, 0, 1, 0],\n",
              " [0, 1, 1, 1, 1, 1, 0]]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wvBrklQ-9pZ4"
      },
      "source": [
        "## Perceptron with Bipolar Step Function\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ouRkizZi9pZ5"
      },
      "source": [
        "#bipolar step function\n",
        "def bipolar_step(x):\n",
        "    return 1.0 if x >= 0.0 else -1.0\n",
        "\n",
        "# Make a prediction with weights\n",
        "def predict(row, weights, flag=False):\n",
        "    yin = weights[0] #Bias\n",
        "    for i in range(len(row)-1):\n",
        "        yin += weights[i + 1] * row[i] #yin = bias + (w1 * X1) + (w2 * X2)\n",
        "    if flag:\n",
        "        print(' theta = ', yin)\n",
        "    y=bipolar_step(yin)\n",
        "    return y\n",
        "\n",
        "#train dataset\n",
        "def train(train, l_rate, n_epoch, mse):\n",
        "    weights = [0.0 for i in range(len(train[0]))]\n",
        "    epoch=0\n",
        "    sum_error = 1.0\n",
        "    while ((epoch < n_epoch) and (sum_error> mse) ):\n",
        "        sum_error = 0.0\n",
        "        for row in train:\n",
        "            prediction = predict(row, weights)\n",
        "            error = row[-1] - prediction\n",
        "            sum_error += error**2\n",
        "            weights[0] = weights[0] + l_rate * error\n",
        "            for i in range(len(row)-1):\n",
        "                weights[i + 1] = weights[i + 1] + l_rate * error * row[i]\n",
        "        print('>epoch=%d, lrate=%.3f, error=%.3f' % (epoch+1, l_rate,sum_error), 'weights=',weights )\n",
        "        epoch+=1\n",
        "    return weights\n",
        "\n",
        "#train weights\n",
        "def train_weights(train, l_rate, n_epoch):\n",
        "    weights = [0.0 for i in range(len(train[0]))]\n",
        "    for epoch in range(n_epoch):\n",
        "        sum_error = 0.0\n",
        "        for row in train:\n",
        "            prediction = predict(row, weights)\n",
        "            error = row[-1] - prediction\n",
        "            sum_error += error**2\n",
        "            weights[0] = weights[0] + l_rate * error\n",
        "            for i in range(len(row)-1):\n",
        "                weights[i + 1] = weights[i + 1] + l_rate * error * row[i]\n",
        "        print('>epoch=%d, lrate=%.3f, error=%.3f' % (epoch, l_rate, sum_error))\n",
        "    return weights\n",
        "    \n",
        "#testing data\n",
        "def testing (data):\n",
        "    for row in data:\n",
        "        prediction = predict(row, weights)\n",
        "        print(\"Expected=%d, Predicted=%d\" % (row[-1], prediction))"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v8spr3ES9pZ7",
        "outputId": "3c56e3fd-da8e-4349-abab-bd728be6b29e"
      },
      "source": [
        "#Implementation\n",
        "print(\"**********DEMO PECEPTRON AND LOGIC 2***********\" )\n",
        "print(\"\\n*** INISIALISASI ***\" )\n",
        "l_rate = 0.1\n",
        "n_epoch = 11\n",
        "mse=0.0001\n",
        "weights = [0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
        "print('>n_epoch=%d, lrate=%.3f, tolErr=%.4f' % (n_epoch, l_rate, mse),'weights=',weights )\n",
        "print(\"\\n*** TRAINING ***\" )\n",
        "weights = train(dataset_with_class, l_rate, n_epoch,mse)\n",
        "print(\"WEIGHT FINAL=\" )\n",
        "print(weights)\n",
        "print(\"\\n*** TEST ***\" )\n",
        "print(' Data input: [x1 x2 x3 x4 x5 x6 t]=', dataset_with_class)\n",
        "print(' Output Perceptron =')\n",
        "testing(dataset_with_class)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**********DEMO PECEPTRON AND LOGIC 2***********\n",
            "\n",
            "*** INISIALISASI ***\n",
            ">n_epoch=11, lrate=0.100, tolErr=0.0001 weights= [0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "\n",
            "*** TRAINING ***\n",
            ">epoch=1, lrate=0.100, error=9.000 weights= [0.1, -0.1, 0.1, 0.1, -0.1, 0.0, 0.2]\n",
            ">epoch=2, lrate=0.100, error=9.000 weights= [0.0, -0.2, 0.0, 0.0, -0.4, 0.0, 0.0]\n",
            ">epoch=3, lrate=0.100, error=9.000 weights= [0.30000000000000004, -0.1, 0.1, 0.1, -0.30000000000000004, 0.2, 0.0]\n",
            ">epoch=4, lrate=0.100, error=5.000 weights= [0.20000000000000004, 0.0, -0.2, 0.0, -0.4, 0.0, 0.0]\n",
            ">epoch=5, lrate=0.100, error=5.000 weights= [0.30000000000000004, -0.1, 0.1, 0.1, -0.30000000000000004, 0.2, 0.0]\n",
            ">epoch=6, lrate=0.100, error=5.000 weights= [0.20000000000000004, 0.0, -0.2, 0.0, -0.4, 0.0, 0.0]\n",
            ">epoch=7, lrate=0.100, error=5.000 weights= [0.30000000000000004, -0.1, 0.1, 0.1, -0.30000000000000004, 0.2, 0.0]\n",
            ">epoch=8, lrate=0.100, error=5.000 weights= [0.20000000000000004, 0.0, -0.2, 0.0, -0.4, 0.0, 0.0]\n",
            ">epoch=9, lrate=0.100, error=5.000 weights= [0.30000000000000004, -0.1, 0.1, 0.1, -0.30000000000000004, 0.2, 0.0]\n",
            ">epoch=10, lrate=0.100, error=5.000 weights= [0.20000000000000004, 0.0, -0.2, 0.0, -0.4, 0.0, 0.0]\n",
            ">epoch=11, lrate=0.100, error=5.000 weights= [0.30000000000000004, -0.1, 0.1, 0.1, -0.30000000000000004, 0.2, 0.0]\n",
            "WEIGHT FINAL=\n",
            "[0.30000000000000004, -0.1, 0.1, 0.1, -0.30000000000000004, 0.2, 0.0]\n",
            "\n",
            "*** TEST ***\n",
            " Data input: [x1 x2 x3 x4 x5 x6 t]= [[1, 0, 0, 0, 1, 0, 1], [0, 1, 1, 1, 1, 0, 0], [0, 0, 1, 0, 0, 1, 1], [0, 0, 1, 0, 1, 0, 1], [0, 1, 0, 0, 0, 1, 1], [1, 0, 1, 0, 1, 1, 1], [0, 0, 1, 1, 0, 0, 0], [0, 1, 0, 1, 0, 0, 0], [1, 0, 0, 1, 0, 1, 0], [0, 1, 1, 1, 1, 1, 0]]\n",
            " Output Perceptron =\n",
            "Expected=1, Predicted=1\n",
            "Expected=0, Predicted=1\n",
            "Expected=1, Predicted=1\n",
            "Expected=1, Predicted=1\n",
            "Expected=1, Predicted=1\n",
            "Expected=1, Predicted=1\n",
            "Expected=0, Predicted=1\n",
            "Expected=0, Predicted=1\n",
            "Expected=0, Predicted=-1\n",
            "Expected=0, Predicted=1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lLHraS-c9pZ-",
        "outputId": "8efc13ff-b7e2-4f4f-b1ec-c4759a41596e"
      },
      "source": [
        "t=dataset[0]\n",
        "print(t)\n",
        "print(weights)\n",
        "prediction = predict(t, weights)\n",
        "print(\"Expected=%d, Predicted=%d\" % (t[-1], prediction))\n",
        "\n",
        "#train weight\n",
        "l_rate = 0.005\n",
        "n_epoch = 11\n",
        "weights = train_weights(dataset_with_class, l_rate, n_epoch)\n",
        "print(weights)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 0, 0, 0, 1, 0]\n",
            "[0.30000000000000004, -0.1, 0.1, 0.1, -0.30000000000000004, 0.2, 0.0]\n",
            "Expected=0, Predicted=1\n",
            ">epoch=0, lrate=0.005, error=9.000\n",
            ">epoch=1, lrate=0.005, error=9.000\n",
            ">epoch=2, lrate=0.005, error=9.000\n",
            ">epoch=3, lrate=0.005, error=5.000\n",
            ">epoch=4, lrate=0.005, error=5.000\n",
            ">epoch=5, lrate=0.005, error=5.000\n",
            ">epoch=6, lrate=0.005, error=5.000\n",
            ">epoch=7, lrate=0.005, error=5.000\n",
            ">epoch=8, lrate=0.005, error=5.000\n",
            ">epoch=9, lrate=0.005, error=5.000\n",
            ">epoch=10, lrate=0.005, error=5.000\n",
            "[0.015, -0.005, 0.005, 0.005, -0.015, 0.01, 0.0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Npzpzsp79paC",
        "outputId": "05cac936-7207-46f1-a138-65362213b024"
      },
      "source": [
        "testing (dataset_with_class)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Expected=1, Predicted=1\n",
            "Expected=0, Predicted=1\n",
            "Expected=1, Predicted=1\n",
            "Expected=1, Predicted=1\n",
            "Expected=1, Predicted=1\n",
            "Expected=1, Predicted=1\n",
            "Expected=0, Predicted=1\n",
            "Expected=0, Predicted=1\n",
            "Expected=0, Predicted=-1\n",
            "Expected=0, Predicted=1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F18egM729paE"
      },
      "source": [
        "## Back Propagation with Logistic Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KwPSEtIJ9paF"
      },
      "source": [
        "dataset_new = train_test_split(dataset,\n",
        "                           dataY,\n",
        "                           test_size = 0.2,\n",
        "                           stratify = dataY)\n",
        "\n",
        "trainX, testX, trainY, testY = dataset_new\n"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ztZVHkvFalV",
        "outputId": "67bed9b6-c6b5-40bb-d2b3-80e741b78610"
      },
      "source": [
        "# def sigmoid(x):\n",
        "#     s=1/(1+np.exp(-x))\n",
        "#     ds=s*(1-s)  \n",
        "#     return s,ds\n",
        "#1. CREATE ANN\n",
        "mlpBP = MLPClassifier(learning_rate_init=0.5, activation='logistic',hidden_layer_sizes=(10,5), max_iter=100, alpha=1e-4, solver='lbfgs', verbose=0, tol=1e-4, random_state=1)\n",
        "\n",
        "#2. TRAINNING\n",
        "mlpBP.fit(trainX, trainY)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPClassifier(activation='logistic', alpha=0.0001, batch_size='auto',\n",
              "              beta_1=0.9, beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
              "              hidden_layer_sizes=(10, 5), learning_rate='constant',\n",
              "              learning_rate_init=0.5, max_fun=15000, max_iter=100, momentum=0.9,\n",
              "              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
              "              random_state=1, shuffle=True, solver='lbfgs', tol=0.0001,\n",
              "              validation_fraction=0.1, verbose=0, warm_start=False)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6URSLRwN9paI"
      },
      "source": [
        "def generateClassificationReport(y_test,y_pred):\n",
        "    print(classification_report(y_test,y_pred))\n",
        "    print(confusion_matrix(y_test,y_pred))\n",
        "    print('accuracy is ',accuracy_score(y_test,y_pred))"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eQHd4RaG9paK",
        "outputId": "42bae7db-9070-4033-a24b-a49eba910d35"
      },
      "source": [
        "#3. PREDICTION\n",
        "print(\"\\n*** PREDICTION TRAINING ***\" )\n",
        "pred_y = mlpBP.predict(trainX)\n",
        "generateClassificationReport(trainY,pred_y)\n",
        "\n",
        "print(\"\\n*** PREDICTION TESTING ***\" )\n",
        "pred_y = mlpBP.predict(testX)\n",
        "generateClassificationReport(testY, pred_y)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "*** PREDICTION TRAINING ***\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         4\n",
            "           1       1.00      1.00      1.00         4\n",
            "\n",
            "    accuracy                           1.00         8\n",
            "   macro avg       1.00      1.00      1.00         8\n",
            "weighted avg       1.00      1.00      1.00         8\n",
            "\n",
            "[[4 0]\n",
            " [0 4]]\n",
            "accuracy is  1.0\n",
            "\n",
            "*** PREDICTION TESTING ***\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         1\n",
            "           1       1.00      1.00      1.00         1\n",
            "\n",
            "    accuracy                           1.00         2\n",
            "   macro avg       1.00      1.00      1.00         2\n",
            "weighted avg       1.00      1.00      1.00         2\n",
            "\n",
            "[[1 0]\n",
            " [0 1]]\n",
            "accuracy is  1.0\n"
          ]
        }
      ]
    }
  ]
}